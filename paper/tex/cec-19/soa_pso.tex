\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}


\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{booktabs} % For formal tables
\usepackage[outdir=./]{epstopdf}
\usepackage{listings}
\usepackage{setspace}
%\doublespacing
\lstset{
  language=C++,
  basicstyle=\ttfamily\footnotesize,
  showspaces=false,
  showtabs=false,
  tabsize=2,
  frame=single,
}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Two Simple Tricks for Fast Cache-Aware Parallel Particle Swarm Optimization}

\author{\IEEEauthorblockN{Jeff Hajewski}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{University of Iowa}\\
Iowa City, Iowa, USA \\
jeffrey-hajewski@uiowa.edu}
\and
\IEEEauthorblockN{Suely Oliveira}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{University of Iowa}\\
Iowa City, Iowa, USA \\
suely-oliveira@uiowa.edu}
}

\maketitle

\begin{abstract}
Particle Swarm Optimization is an example of a trivially parallelizable
algorithm where good performance gains can be achieved through the use of a few
OpenMP pragmas. Writing an efficient parallel PSO algorithm, however, is much more
challenging because although particle updates can occur independently, they
rely on a shared global state (the globally best particle). The difficulty of
maintaining this global state can be seen in the large body of work studying the
parallelization of PSO -- almost uniformly these algorithms rely on a global
synchronization step, which can result in idle cores and reduced parallel
efficiency. In this work, we introduce two techniques for implementing a fast,
cache-aware parallel PSO algorithm: batching the creation of the random weights
and reducing critical section contention via a relaxed consistency guarantee.
Our technique shows impressive performance improvements over prior work, seeing
more than 60\% speed-up over naive parallelization and more than 10\% speed-up
over the cache-aware algorithm. This speed comes at a cost; while our method
quickly reaches an approximate solution, it struggles in environments requiring
a high level of resolution. Despite these trade-offs, our method is both
easy to understand and implement and is widely transferable to other
swarm intelligence algorithms.
\end{abstract}

\begin{IEEEkeywords}
Particle Swarm Optimization, Data Oriented Design, Parallel PSO
\end{IEEEkeywords}

\input{body}

\bibliographystyle{ieeetr}
\bibliography{bibliography}
\end{document}
